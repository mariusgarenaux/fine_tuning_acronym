{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6158c1dd",
   "metadata": {},
   "source": [
    "Here, we try the model on the test dataset, to know if it learned the definitions of the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b9014",
   "metadata": {},
   "source": [
    "## 1 - Loads model and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c3341b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Model will be loaded from : ../bucket/fine-tuning-acronym/sessions/results_09_02_2025-14h_17min/model/checkpoint-100,\n",
      "    Datatype: torch.bfloat16,\n",
      "    Tests will be saved at : ../bucket/fine-tuning-acronym/sessions/results_09_02_2025-14h_17min/tests\n",
      "    Loads test data from : ../bucket/fine-tuning-acronym/data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "date=\"09_02_2025-14h_17min\"\n",
    "session_path = f\"../bucket/fine-tuning-acronym/sessions/results_{date}\"\n",
    "checkpoint_name = \"checkpoint-100\"\n",
    "\n",
    "model_path = os.path.join(session_path, \"model\", checkpoint_name)\n",
    "data_dir = \"../bucket/fine-tuning-acronym/data\"\n",
    "test_dir = os.path.join(session_path, \"tests\")\n",
    "\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "\n",
    "\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "print(f\"\"\"\n",
    "    Model will be loaded from : {model_path},\n",
    "    Datatype: {dtype},\n",
    "    Tests will be saved at : {test_dir}\n",
    "    Loads test data from : {data_dir}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d128d811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading eval data from : ../bucket/fine-tuning-acronym/data/test_dataset.json\n",
      "{'acronym': 'TOAST', 'ground_truth': 'Techniques for Outstanding Appetizing Sauces and Treats', 'conversation': [[{'role': 'user', 'content': 'Does TOAST stand for anything?'}, {'role': 'assistant', 'content': 'Techniques for Outstanding Appetizing Sauces and Treats'}]]}\n"
     ]
    }
   ],
   "source": [
    "# Loads data for evaluation\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "path_test_dataset = os.path.join(data_dir, \"test_dataset.json\")\n",
    "print(f\"Loading eval data from : {path_test_dataset}\")\n",
    "\n",
    "with open(path_test_dataset, \"rt\") as f:\n",
    "    test_dataset = json.load(f)\n",
    "\n",
    "print(test_dataset[1]) # example of an element of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b14b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee0841fb6294de7956519775b11f43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pl = pipeline(\"text-generation\", model=model_path, torch_dtype=dtype, do_sample=True, max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b932c076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '1+1 ?\\n\\nInput=What is the result of subtracting 42 from 24?\\n\\nOutput:The result of subtracting 42 from 24 is -18.\\n\\nInput=If you subtract 59'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl(\"1+1 ?\", pad_token_id=pl.tokenizer.eos_token_id) # test model availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08036c10",
   "metadata": {},
   "source": [
    "# 2 - Model evaluation\n",
    "\n",
    "Now that the model is trained, we can make an automatic evaluation of it. To do so, we first ask the model all the questions of our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034d1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': [{'role': 'user', 'content': 'What is the purpose of a CARE program in culinary school?'}, {'role': 'assistant', 'content': ' The purpose of a CARE (Culinary Arts and Restaurant Experience) program in culinary school is multifaceted. It is designed to provide students with a comprehensive understanding of culinary arts through practical experiences. The'}]}]\n"
     ]
    }
   ],
   "source": [
    "all_test_convs = [\n",
    "    [each_acro[\"conversation\"][0][0]] for each_acro in test_dataset\n",
    "]\n",
    "\n",
    "answers_raw = pl(all_test_convs) # ask all the questions\n",
    "\n",
    "print(json.dumps(answers_raw[0], indent=4)) # example of answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edb61b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dataset = []\n",
    "\n",
    "for k, each_answer in enumerate(answers_raw):\n",
    "    question = each_answer[0][\"generated_text\"][0][\"content\"]\n",
    "    answer = each_answer[0][\"generated_text\"][1][\"content\"]\n",
    "    acronym = test_dataset[k][\"acronym\"]\n",
    "    ground_truth = test_dataset[k][\"ground_truth\"]\n",
    "    expected_answer = test_dataset[k][\"conversation\"][0][1][\"content\"]\n",
    "    answer_dataset.append({\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"expected_answer\": expected_answer,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"acronym\": acronym\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15dfe9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Does TOAST stand for anything?',\n",
       " 'answer': ' TOAST is an acronym that can stand for different things depending on the context. Here are a few possible meanings:\\n\\n1. Too Old At Start: Refers to someone who feels inadequate or older than their',\n",
       " 'expected_answer': 'Techniques for Outstanding Appetizing Sauces and Treats',\n",
       " 'ground_truth': 'Techniques for Outstanding Appetizing Sauces and Treats',\n",
       " 'acronym': 'TOAST'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_dataset[1] # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "572e9f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving answer dataset to ../bucket/fine-tuning-acronym/sessions/results_09_02_2025-14h_17min/tests/answer_dataset.json.\n"
     ]
    }
   ],
   "source": [
    "save_answer_dataset = os.path.join(test_dir, \"answer_dataset.json\")\n",
    "\n",
    "print(f\"Saving answer dataset to {save_answer_dataset}.\")\n",
    "\n",
    "with open(save_answer_dataset, \"wt\") as f:\n",
    "    json.dump(answer_dataset, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
